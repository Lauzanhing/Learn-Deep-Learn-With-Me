### Hadoop配置文件修改

- Hadoop安装主要就是配置文件修改
  
- 一般在主节点修改/然后scp下发给其他从节点机器。
  
- hadoop-env.sh

  - vi Hadoop-env.sh
  - Export JAVA_HOME=....

- Core-site.xml

  - HDFS的NameNode的地址/即Hadoop所用的文件系统

    ```html
    <proerty>
    	<name>fs.defaultFS</name>
      	<value>hdfs://node-1:9000</value>
    </proerty>
    ```

  - 运行时产生文件的存储目录

  - ```html
    <property>
    	<name>hadoop.tmp.dir</name>
      	<value>home/hadoop/xxx</value>
    </property>
    ```

- hdfs-site.xml

  - HDFS副本数量

  - ```html
    <property>
    	<name>dfs.replication</name>
      	<value>2</value>
    </property>
    ```

  - secondaryNode-address

  - ```html
    <property>
    	<name>dfs.namenode.secondary.http-address</name>
      	<value>node-22:50090</value>
    </property>
    ```

- mapred-site.xml

  - 指定mr运行时框架，这里指定在yarn上，默认是local

  - ```html
    <property>
    	<name>mapreduce.framework.name</name>
      	<value>yarn</value>
    </property>
    ```

- yarn-site.xml

  - 指定YARN的ResourceManager的地址

  - ```html
    <property>
    	<name>yarn.resourcemanager.hostname</name>
      	<value>node-1</value>
    </property>
    ```

  - 配置成mapreduce_shuffle（NodeManager上运行的附属服务）

  - ```html
    <property>
    	<name>yarn.nodemanager.aux-services</name>
      	<value>mapreduce_shuffle</value>
    </property>
    ```

- slaves文件,写从节点所在的主机名字

  - ```
    vi slaves
    node-2
    node-3
    ```

- 将hadoop添加到环境变量

  - vim /etc/proflie
  - ![](https://imgkr.cn-bj.ufileos.com/bc8a8236-b41c-44a9-bf94-19b41d5aad95.png)
  - source /etc/proflie



- 发送配置文件
  - scp -r /export/server/hadoop-2.7.4/ root@node-2:/export/server/
  - scp -r /export/server/hadoop-2.7.4/ root@node-3:/export/server/
  - 可以写个脚本发送
  - 发送环境变量
    - scp -r /etc/profile root@ node-2:/etc/
    - source /etc/profile

关于hadoop的配置文件：

- ***-default.xml：这里配置了hadoop默认的配置选项
- 用户没有更改 那么这里的选项将会生效
- ***-site.xml：这里配置了用户需要自定义的配置选项
- site中配置选项优先级>Default中的，如果有配置的话就会覆盖默认的配置选项
- 查看配置是否过期 Deprecated Properties

